# Explaining_ML_models

Using Shapley value, explained the outputs of complex ML models and clustering results. (Master's thesis)

**Contributors:** Ragács Attila, Dr. Kovács Edith Alice (supervisor)

**Goal:** Take complex, "black-box" machine learning models and explain their outputs with the Shapley value from game theory. In this sense the input variables are the players and the output is the value of the game. This way we can contribute an effect to each variable and define an importance measure. We also worked extensively with clustering, trying to determine which variables help forming or fracturing each cluster. Finally we applied these methods on Hungarian settlement data. Managed to explain where each settlement's financial power or weakness originates from, also we characterized 5 clusters resulting from k-means clustering. 

**Files:**
- **Diplomamunka_kivonat_RA.pdf:** short description of the thesis (Hungarian)
- **Diplomamunka_vegleges_RA.pdf:** full documentation of the work, the thesis itself (Hungarian)
- **Diplomamunka_1_cShapley.ipynb:** notebook of the clustering part
- **Diplomamunka2_shap_reg.ipynb:** notebook of the regression analysis

